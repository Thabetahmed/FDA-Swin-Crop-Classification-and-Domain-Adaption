{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6862e3fb",
   "metadata": {},
   "source": [
    "# Sentinel-2 Data Extraction for Algerian Crop Samples (2023)\n",
    "\n",
    "This notebook extracts Sentinel-2 imagery from Google Earth Engine for the Algerian field samples.\n",
    "\n",
    "**Parameters:**\n",
    "- **Year:** 2023 (from XML metadata: CreaDate=20230126)\n",
    "- **Time Range:** January - April 2023 (growing season for cereals)\n",
    "- **Bands:** 10 bands matching PASTIS format (B2, B3, B4, B5, B6, B7, B8, B8A, B11, B12)\n",
    "- **Patch Size:** 128×128 pixels at 10m resolution\n",
    "- **Output Format:** NumPy arrays (.npy) matching PASTIS structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "745276e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geemap already installed\n",
      "earthengine-api already installed\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Install geemap if not installed\n",
    "try:\n",
    "    import geemap\n",
    "    print(\"geemap already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing geemap...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"geemap\", \"-q\"])\n",
    "    import geemap\n",
    "    print(\"geemap installed successfully\")\n",
    "\n",
    "# Install earthengine-api if not installed\n",
    "try:\n",
    "    import ee\n",
    "    print(\"earthengine-api already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing earthengine-api...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"earthengine-api\", \"-q\"])\n",
    "    import ee\n",
    "    print(\"earthengine-api installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab592a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEE initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "# Authenticate and Initialize Google Earth Engine\n",
    "import ee\n",
    "import geemap\n",
    "\n",
    "# Initialize with project ID\n",
    "try:\n",
    "    ee.Initialize(project='mythical-sweep-471412-h5')\n",
    "    print(\"GEE initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Authenticating with Google Earth Engine...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(project='mythical-sweep-471412-h5')\n",
    "    print(\"GEE authenticated and initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819c24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 117\n",
      "  - Training cereal: 1\n",
      "  - Training non-cereal: 62\n",
      "  - Validation cereal: 1\n",
      "  - Validation non-cereal: 53\n",
      "\n",
      "Bounds: [-0.86667757 34.96964575 -0.53314745 35.25219505]\n",
      "CRS: EPSG:4326\n"
     ]
    }
   ],
   "source": [
    "# Load shapefiles and prepare data\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "BASE_DIR = Path('/home/crop/Desktop/crop2')\n",
    "SAMPLES_DIR = BASE_DIR / 'Samples_cereal_In-situ Algerian' / 'Samples_cereal'\n",
    "OUTPUT_DIR = BASE_DIR / 'output' / 'algeria_s2_data'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load all shapefiles\n",
    "samples_cereal = gpd.read_file(SAMPLES_DIR / 'samples_cereal.shp')\n",
    "samples_non_cereal = gpd.read_file(SAMPLES_DIR / 'samples_non_cereal.shp')\n",
    "validation_cereal = gpd.read_file(SAMPLES_DIR / 'validation_cereal.shp')\n",
    "validation_non_cereal = gpd.read_file(SAMPLES_DIR / 'validation_non_cereal.shp')\n",
    "\n",
    "# Add class labels\n",
    "samples_cereal['class'] = 1  # cereal\n",
    "samples_non_cereal['class'] = 0  # non-cereal\n",
    "validation_cereal['class'] = 1\n",
    "validation_non_cereal['class'] = 0\n",
    "\n",
    "# Add dataset type\n",
    "samples_cereal['split'] = 'train'\n",
    "samples_non_cereal['split'] = 'train'\n",
    "validation_cereal['split'] = 'validation'\n",
    "validation_non_cereal['split'] = 'validation'\n",
    "\n",
    "# Combine all samples\n",
    "all_samples = gpd.GeoDataFrame(\n",
    "    pd.concat([samples_cereal, samples_non_cereal, validation_cereal, validation_non_cereal], ignore_index=True),\n",
    "    crs=samples_cereal.crs\n",
    ")\n",
    "\n",
    "# Add unique ID\n",
    "all_samples['patch_id'] = range(len(all_samples))\n",
    "\n",
    "print(f\"Total samples: {len(all_samples)}\")\n",
    "print(f\"  - Training cereal: {len(samples_cereal)}\")\n",
    "print(f\"  - Training non-cereal: {len(samples_non_cereal)}\")\n",
    "print(f\"  - Validation cereal: {len(validation_cereal)}\")\n",
    "print(f\"  - Validation non-cereal: {len(validation_non_cereal)}\")\n",
    "print(f\"\\nBounds: {all_samples.total_bounds}\")\n",
    "print(f\"CRS: {all_samples.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bfb49a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Parameters:\n",
      "  - Date Range: 2023-01-01 to 2023-04-30\n",
      "  - Bands: ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
      "  - Patch Size: 128x128 pixels\n",
      "  - Resolution: 10m\n",
      "  - Spatial extent: 1.28km x 1.28km per patch\n"
     ]
    }
   ],
   "source": [
    "# Define Sentinel-2 data extraction parameters\n",
    "import pandas as pd\n",
    "\n",
    "# Time range for growing season (Jan-April 2023)\n",
    "START_DATE = '2023-01-01'\n",
    "END_DATE = '2023-04-30'\n",
    "\n",
    "# Bands to extract (matching PASTIS format)\n",
    "S2_BANDS = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
    "\n",
    "# Patch size\n",
    "PATCH_SIZE = 128  # 128x128 pixels at 10m = 1.28km x 1.28km\n",
    "\n",
    "# Resolution (meters)\n",
    "RESOLUTION = 10\n",
    "\n",
    "print(f\"Extraction Parameters:\")\n",
    "print(f\"  - Date Range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"  - Bands: {S2_BANDS}\")\n",
    "print(f\"  - Patch Size: {PATCH_SIZE}x{PATCH_SIZE} pixels\")\n",
    "print(f\"  - Resolution: {RESOLUTION}m\")\n",
    "print(f\"  - Spatial extent: {PATCH_SIZE * RESOLUTION / 1000:.2f}km x {PATCH_SIZE * RESOLUTION / 1000:.2f}km per patch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d57b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample polygon creates 40 patch(es)\n",
      "First patch bounds: [np.float64(-0.8656314197659908), 34.971679731234644, np.float64(-0.8515983487718158), 34.983259249960895]\n"
     ]
    }
   ],
   "source": [
    "# Functions to create 128x128 patches from polygons\n",
    "def get_patch_bounds(centroid_x, centroid_y, patch_size=128, resolution=10):\n",
    "    \"\"\"Calculate patch bounds centered on a point\"\"\"\n",
    "    half_extent = (patch_size * resolution) / 2  # meters\n",
    "    # Convert degrees to meters (approximate for Algeria ~35°N)\n",
    "    deg_per_meter_lon = 1 / (111320 * np.cos(np.radians(centroid_y)))\n",
    "    deg_per_meter_lat = 1 / 110540\n",
    "    \n",
    "    half_extent_lon = half_extent * deg_per_meter_lon\n",
    "    half_extent_lat = half_extent * deg_per_meter_lat\n",
    "    \n",
    "    return [\n",
    "        centroid_x - half_extent_lon,  # min_x\n",
    "        centroid_y - half_extent_lat,  # min_y\n",
    "        centroid_x + half_extent_lon,  # max_x\n",
    "        centroid_y + half_extent_lat   # max_y\n",
    "    ]\n",
    "\n",
    "def split_large_polygon(geometry, patch_size=128, resolution=10):\n",
    "    \"\"\"Split a large polygon into multiple 128x128 patches\"\"\"\n",
    "    from shapely.geometry import box\n",
    "    \n",
    "    bounds = geometry.bounds  # minx, miny, maxx, maxy\n",
    "    centroid = geometry.centroid\n",
    "    \n",
    "    # Calculate polygon extent in meters\n",
    "    extent_x_m = (bounds[2] - bounds[0]) * 111320 * np.cos(np.radians(centroid.y))\n",
    "    extent_y_m = (bounds[3] - bounds[1]) * 110540\n",
    "    \n",
    "    patch_extent_m = patch_size * resolution  # 1280m for 128x128 at 10m\n",
    "    \n",
    "    # If polygon fits in one patch, return single centered patch\n",
    "    if extent_x_m <= patch_extent_m and extent_y_m <= patch_extent_m:\n",
    "        return [get_patch_bounds(centroid.x, centroid.y, patch_size, resolution)]\n",
    "    \n",
    "    # Otherwise, create grid of patches covering the polygon\n",
    "    patches = []\n",
    "    \n",
    "    # Number of patches needed in each direction\n",
    "    n_patches_x = int(np.ceil(extent_x_m / patch_extent_m))\n",
    "    n_patches_y = int(np.ceil(extent_y_m / patch_extent_m))\n",
    "    \n",
    "    # Calculate step size in degrees\n",
    "    deg_per_meter_lon = 1 / (111320 * np.cos(np.radians(centroid.y)))\n",
    "    deg_per_meter_lat = 1 / 110540\n",
    "    step_lon = patch_extent_m * deg_per_meter_lon\n",
    "    step_lat = patch_extent_m * deg_per_meter_lat\n",
    "    \n",
    "    # Start from bottom-left of bounding box\n",
    "    start_x = bounds[0] + step_lon / 2\n",
    "    start_y = bounds[1] + step_lat / 2\n",
    "    \n",
    "    for i in range(n_patches_x):\n",
    "        for j in range(n_patches_y):\n",
    "            patch_center_x = start_x + i * step_lon\n",
    "            patch_center_y = start_y + j * step_lat\n",
    "            \n",
    "            # Check if patch center is within or near the polygon\n",
    "            patch_bounds = get_patch_bounds(patch_center_x, patch_center_y, patch_size, resolution)\n",
    "            patch_box = box(patch_bounds[0], patch_bounds[1], patch_bounds[2], patch_bounds[3])\n",
    "            \n",
    "            if geometry.intersects(patch_box):\n",
    "                patches.append(patch_bounds)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "# Test on first sample\n",
    "test_geom = all_samples.iloc[0].geometry\n",
    "test_patches = split_large_polygon(test_geom)\n",
    "print(f\"Sample polygon creates {len(test_patches)} patch(es)\")\n",
    "print(f\"First patch bounds: {test_patches[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaa27217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches to extract: 196\n",
      "\n",
      "Patches by class:\n",
      "split       class\n",
      "train       0        62\n",
      "            1        40\n",
      "validation  0        53\n",
      "            1        41\n",
      "dtype: int64\n",
      "\n",
      "Patches by original sample:\n",
      "  Min patches per sample: 1\n",
      "  Max patches per sample: 41\n",
      "  Mean patches per sample: 1.68\n"
     ]
    }
   ],
   "source": [
    "# Create all patches from all samples\n",
    "all_patches = []\n",
    "\n",
    "for idx, row in all_samples.iterrows():\n",
    "    patches = split_large_polygon(row.geometry)\n",
    "    for p_idx, patch_bounds in enumerate(patches):\n",
    "        all_patches.append({\n",
    "            'original_id': row['patch_id'],\n",
    "            'patch_idx': p_idx,\n",
    "            'class': row['class'],\n",
    "            'split': row['split'],\n",
    "            'bounds': patch_bounds,\n",
    "            'center_lon': (patch_bounds[0] + patch_bounds[2]) / 2,\n",
    "            'center_lat': (patch_bounds[1] + patch_bounds[3]) / 2\n",
    "        })\n",
    "\n",
    "patches_df = pd.DataFrame(all_patches)\n",
    "patches_df['unique_id'] = range(len(patches_df))\n",
    "\n",
    "print(f\"Total patches to extract: {len(patches_df)}\")\n",
    "print(f\"\\nPatches by class:\")\n",
    "print(patches_df.groupby(['split', 'class']).size())\n",
    "print(f\"\\nPatches by original sample:\")\n",
    "print(f\"  Min patches per sample: {patches_df.groupby('original_id').size().min()}\")\n",
    "print(f\"  Max patches per sample: {patches_df.groupby('original_id').size().max()}\")\n",
    "print(f\"  Mean patches per sample: {patches_df.groupby('original_id').size().mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d891e899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEE extraction functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# GEE extraction functions\n",
    "def get_s2_median_composite(bounds, start_date, end_date, bands):\n",
    "    \"\"\"\n",
    "    Get median composite of Sentinel-2 imagery for a given region and time period.\n",
    "    Uses Sentinel-2 Surface Reflectance (SR) data with cloud masking.\n",
    "    \"\"\"\n",
    "    # Create region geometry\n",
    "    region = ee.Geometry.Rectangle(bounds)\n",
    "    \n",
    "    # Load Sentinel-2 SR collection\n",
    "    s2_sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "        .filterBounds(region) \\\n",
    "        .filterDate(start_date, end_date) \\\n",
    "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
    "    \n",
    "    # Cloud masking function using SCL band\n",
    "    def mask_clouds(image):\n",
    "        scl = image.select('SCL')\n",
    "        # Keep: vegetation (4), bare soil (5), water (6)\n",
    "        # Mask: clouds (8,9,10), cloud shadow (3), snow (11)\n",
    "        mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6))\n",
    "        return image.updateMask(mask)\n",
    "    \n",
    "    # Apply cloud mask and compute median\n",
    "    s2_masked = s2_sr.map(mask_clouds)\n",
    "    median_composite = s2_masked.select(bands).median()\n",
    "    \n",
    "    return median_composite, region\n",
    "\n",
    "def extract_patch_data(composite, region, patch_size=128, resolution=10):\n",
    "    \"\"\"\n",
    "    Extract patch data as numpy array from GEE.\n",
    "    Returns array of shape (bands, height, width).\n",
    "    \"\"\"\n",
    "    # Sample the image at the region\n",
    "    try:\n",
    "        # Get the data as a numpy array via geemap\n",
    "        data = geemap.ee_to_numpy(\n",
    "            composite,\n",
    "            region=region,\n",
    "            scale=resolution,\n",
    "            bands=S2_BANDS\n",
    "        )\n",
    "        \n",
    "        if data is None:\n",
    "            return None\n",
    "            \n",
    "        # Reshape to (bands, height, width) to match PASTIS format\n",
    "        if len(data.shape) == 3:\n",
    "            data = np.transpose(data, (2, 0, 1))\n",
    "        \n",
    "        # Ensure 128x128 size (crop or pad if necessary)\n",
    "        if data.shape[1] != patch_size or data.shape[2] != patch_size:\n",
    "            # Create padded/cropped array\n",
    "            result = np.zeros((len(S2_BANDS), patch_size, patch_size), dtype=np.int16)\n",
    "            h, w = min(data.shape[1], patch_size), min(data.shape[2], patch_size)\n",
    "            result[:, :h, :w] = data[:, :h, :w]\n",
    "            return result\n",
    "            \n",
    "        return data.astype(np.int16)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"GEE extraction functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f385cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing extraction for patch with bounds: [np.float64(-0.8656314197659908), 34.971679731234644, np.float64(-0.8515983487718158), 34.983259249960895]\n",
      "\n",
      "Composite bands: ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B8A', 'B11', 'B12']\n",
      "\n",
      "Download URL obtained successfully!\n",
      "Downloading test patch...\n",
      "Downloaded data shape: (130, 158)\n",
      "Data type: [('B2', '<f8'), ('B3', '<f8'), ('B4', '<f8'), ('B5', '<f8'), ('B6', '<f8'), ('B7', '<f8'), ('B8', '<f8'), ('B8A', '<f8'), ('B11', '<f8'), ('B12', '<f8')]\n",
      "Error: ufunc 'minimum' did not contain a loop with signature matching types (dtype([('B2', '<f8'), ('B3', '<f8'), ('B4', '<f8'), ('B5', '<f8'), ('B6', '<f8'), ('B7', '<f8'), ('B8', '<f8'), ('B8A', '<f8'), ('B11', '<f8'), ('B12', '<f8')]), dtype([('B2', '<f8'), ('B3', '<f8'), ('B4', '<f8'), ('B5', '<f8'), ('B6', '<f8'), ('B7', '<f8'), ('B8', '<f8'), ('B8A', '<f8'), ('B11', '<f8'), ('B12', '<f8')])) -> None\n"
     ]
    }
   ],
   "source": [
    "# Test extraction on one patch\n",
    "test_bounds = patches_df.iloc[0]['bounds']\n",
    "print(f\"Testing extraction for patch with bounds: {test_bounds}\")\n",
    "\n",
    "# Get median composite\n",
    "composite, region = get_s2_median_composite(test_bounds, START_DATE, END_DATE, S2_BANDS)\n",
    "\n",
    "# Check image info\n",
    "info = composite.getInfo()\n",
    "print(f\"\\nComposite bands: {[b['id'] for b in info['bands']]}\")\n",
    "\n",
    "# Try to extract as numpy array using getDownloadURL method\n",
    "try:\n",
    "    # Alternative method: use ee.data.computePixels\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "    \n",
    "    # Get download URL for the region\n",
    "    url = composite.getDownloadURL({\n",
    "        'bands': S2_BANDS,\n",
    "        'region': region,\n",
    "        'scale': RESOLUTION,\n",
    "        'format': 'NPY'\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nDownload URL obtained successfully!\")\n",
    "    print(f\"Downloading test patch...\")\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        test_data = np.load(BytesIO(response.content))\n",
    "        print(f\"Downloaded data shape: {test_data.shape}\")\n",
    "        print(f\"Data type: {test_data.dtype}\")\n",
    "        print(f\"Value range: {test_data.min()} to {test_data.max()}\")\n",
    "    else:\n",
    "        print(f\"Download failed: {response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44137596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download function defined!\n"
     ]
    }
   ],
   "source": [
    "# Full extraction function with proper patch handling\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "def download_patch(bounds, start_date, end_date, bands, resolution=10, patch_size=128):\n",
    "    \"\"\"\n",
    "    Download a single patch from GEE as numpy array.\n",
    "    Returns array of shape (bands, height, width) matching PASTIS format.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create region geometry\n",
    "        region = ee.Geometry.Rectangle(bounds)\n",
    "        \n",
    "        # Load Sentinel-2 SR collection with cloud filtering\n",
    "        s2_sr = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
    "            .filterBounds(region) \\\n",
    "            .filterDate(start_date, end_date) \\\n",
    "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
    "        \n",
    "        # Cloud masking function\n",
    "        def mask_clouds(image):\n",
    "            scl = image.select('SCL')\n",
    "            mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6)).Or(scl.eq(2))  # veg, soil, water, dark\n",
    "            return image.updateMask(mask)\n",
    "        \n",
    "        # Compute median composite\n",
    "        s2_masked = s2_sr.map(mask_clouds)\n",
    "        composite = s2_masked.select(bands).median()\n",
    "        \n",
    "        # Get download URL\n",
    "        url = composite.getDownloadURL({\n",
    "            'bands': bands,\n",
    "            'region': region,\n",
    "            'scale': resolution,\n",
    "            'format': 'NPY'\n",
    "        })\n",
    "        \n",
    "        # Download data\n",
    "        response = requests.get(url, timeout=60)\n",
    "        if response.status_code != 200:\n",
    "            return None, f\"HTTP {response.status_code}\"\n",
    "        \n",
    "        # Load numpy array\n",
    "        data = np.load(BytesIO(response.content))\n",
    "        \n",
    "        # Handle structured array (from GEE NPY format)\n",
    "        if data.dtype.names is not None:\n",
    "            # Convert structured array to regular array\n",
    "            arrays = [data[name] for name in data.dtype.names]\n",
    "            data = np.stack(arrays, axis=0)\n",
    "        elif len(data.shape) == 3 and data.shape[2] == len(bands):\n",
    "            # Transpose from (H, W, C) to (C, H, W)\n",
    "            data = np.transpose(data, (2, 0, 1))\n",
    "        \n",
    "        # Ensure correct patch size\n",
    "        n_bands = len(bands)\n",
    "        result = np.zeros((n_bands, patch_size, patch_size), dtype=np.int16)\n",
    "        \n",
    "        h = min(data.shape[1], patch_size)\n",
    "        w = min(data.shape[2], patch_size)\n",
    "        \n",
    "        # Center the data if smaller than patch_size\n",
    "        start_h = (patch_size - h) // 2\n",
    "        start_w = (patch_size - w) // 2\n",
    "        \n",
    "        result[:, start_h:start_h+h, start_w:start_w+w] = data[:, :h, :w].astype(np.int16)\n",
    "        \n",
    "        return result, None\n",
    "        \n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "print(\"Download function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61285b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting extraction of 196 patches...\n",
      "Output directory: /home/crop/Desktop/crop2/output/algeria_s2_data\n",
      "Time period: 2023-01-01 to 2023-04-30\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading patches:  18%|█▊        | 36/196 [06:05<27:02, 10.14s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m bounds = row[\u001b[33m'\u001b[39m\u001b[33mbounds\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Download patch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m data, error = \u001b[43mdownload_patch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbands\u001b[49m\u001b[43m=\u001b[49m\u001b[43mS2_BANDS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresolution\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRESOLUTION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATCH_SIZE\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# Save to .npy file (matching PASTIS format)\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# PASTIS format: (Time, Bands, Height, Width) - we have single time, so (1, 10, 128, 128)\u001b[39;00m\n\u001b[32m     36\u001b[39m     data_with_time = data[np.newaxis, :, :, :]  \u001b[38;5;66;03m# Add time dimension\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mdownload_patch\u001b[39m\u001b[34m(bounds, start_date, end_date, bands, resolution, patch_size)\u001b[39m\n\u001b[32m     33\u001b[39m url = composite.getDownloadURL({\n\u001b[32m     34\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mbands\u001b[39m\u001b[33m'\u001b[39m: bands,\n\u001b[32m     35\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mregion\u001b[39m\u001b[33m'\u001b[39m: region,\n\u001b[32m     36\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mscale\u001b[39m\u001b[33m'\u001b[39m: resolution,\n\u001b[32m     37\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mNPY\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     38\u001b[39m })\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Download data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHTTP \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/requests/sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/requests/models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/urllib3/response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1094\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/urllib3/response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/urllib3/response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/crop2/myenv/lib/python3.12/site-packages/urllib3/response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/http/client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    709\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1252\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1249\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1250\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1251\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1252\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1102\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Extract all patches and save to files\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output directories\n",
    "DATA_DIR = OUTPUT_DIR / 'DATA_S2'\n",
    "ANNOTATIONS_DIR = OUTPUT_DIR / 'ANNOTATIONS'\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "ANNOTATIONS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Track results\n",
    "successful_downloads = []\n",
    "failed_downloads = []\n",
    "\n",
    "print(f\"Starting extraction of {len(patches_df)} patches...\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Time period: {START_DATE} to {END_DATE}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for idx, row in tqdm(patches_df.iterrows(), total=len(patches_df), desc=\"Downloading patches\"):\n",
    "    patch_id = row['unique_id']\n",
    "    bounds = row['bounds']\n",
    "    \n",
    "    # Download patch\n",
    "    data, error = download_patch(\n",
    "        bounds=bounds,\n",
    "        start_date=START_DATE,\n",
    "        end_date=END_DATE,\n",
    "        bands=S2_BANDS,\n",
    "        resolution=RESOLUTION,\n",
    "        patch_size=PATCH_SIZE\n",
    "    )\n",
    "    \n",
    "    if data is not None:\n",
    "        # Save to .npy file (matching PASTIS format)\n",
    "        # PASTIS format: (Time, Bands, Height, Width) - we have single time, so (1, 10, 128, 128)\n",
    "        data_with_time = data[np.newaxis, :, :, :]  # Add time dimension\n",
    "        \n",
    "        filename = f\"S2_{patch_id:05d}.npy\"\n",
    "        np.save(DATA_DIR / filename, data_with_time)\n",
    "        \n",
    "        successful_downloads.append({\n",
    "            'patch_id': patch_id,\n",
    "            'original_id': row['original_id'],\n",
    "            'class': row['class'],\n",
    "            'split': row['split'],\n",
    "            'center_lon': row['center_lon'],\n",
    "            'center_lat': row['center_lat'],\n",
    "            'filename': filename\n",
    "        })\n",
    "    else:\n",
    "        failed_downloads.append({\n",
    "            'patch_id': patch_id,\n",
    "            'error': error\n",
    "        })\n",
    "    \n",
    "    # Small delay to avoid rate limiting\n",
    "    time.sleep(0.5)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Extraction complete!\")\n",
    "print(f\"  Successful: {len(successful_downloads)}\")\n",
    "print(f\"  Failed: {len(failed_downloads)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata and annotations (matching PASTIS format)\n",
    "import json\n",
    "\n",
    "# Create metadata DataFrame\n",
    "metadata_df = pd.DataFrame(successful_downloads)\n",
    "\n",
    "# Save as GeoJSON (similar to PASTIS metadata.geojson)\n",
    "if len(successful_downloads) > 0:\n",
    "    metadata_gdf = gpd.GeoDataFrame(\n",
    "        metadata_df,\n",
    "        geometry=gpd.points_from_xy(metadata_df['center_lon'], metadata_df['center_lat']),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    metadata_gdf.to_file(OUTPUT_DIR / 'metadata.geojson', driver='GeoJSON')\n",
    "    \n",
    "    # Save class labels for each patch (ANNOTATIONS)\n",
    "    for _, row in metadata_df.iterrows():\n",
    "        patch_id = row['patch_id']\n",
    "        class_label = row['class']\n",
    "        # Save as single value array (like ParcelIDs in PASTIS)\n",
    "        np.save(ANNOTATIONS_DIR / f'Labels_{patch_id:05d}.npy', np.array([class_label]))\n",
    "    \n",
    "    # Save summary JSON\n",
    "    summary = {\n",
    "        'extraction_date': datetime.now().isoformat(),\n",
    "        'source': 'Sentinel-2 SR Harmonized (GEE)',\n",
    "        'time_range': {'start': START_DATE, 'end': END_DATE},\n",
    "        'bands': S2_BANDS,\n",
    "        'resolution_m': RESOLUTION,\n",
    "        'patch_size': PATCH_SIZE,\n",
    "        'total_patches': len(successful_downloads),\n",
    "        'classes': {'0': 'non-cereal', '1': 'cereal'},\n",
    "        'splits': metadata_df['split'].value_counts().to_dict(),\n",
    "        'class_distribution': metadata_df['class'].value_counts().to_dict()\n",
    "    }\n",
    "    \n",
    "    with open(OUTPUT_DIR / 'extraction_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    print(\"Metadata and annotations saved!\")\n",
    "    print(f\"\\nDataset Summary:\")\n",
    "    print(f\"  - Total patches: {len(successful_downloads)}\")\n",
    "    print(f\"  - Training patches: {len(metadata_df[metadata_df['split']=='train'])}\")\n",
    "    print(f\"  - Validation patches: {len(metadata_df[metadata_df['split']=='validation'])}\")\n",
    "    print(f\"  - Cereal patches: {len(metadata_df[metadata_df['class']==1])}\")\n",
    "    print(f\"  - Non-cereal patches: {len(metadata_df[metadata_df['class']==0])}\")\n",
    "else:\n",
    "    print(\"No successful downloads to save metadata for.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d990601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some extracted patches\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and visualize first few patches\n",
    "if len(successful_downloads) > 0:\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, row in enumerate(successful_downloads[:8]):\n",
    "        patch_file = DATA_DIR / row['filename']\n",
    "        data = np.load(patch_file)  # Shape: (1, 10, 128, 128)\n",
    "        \n",
    "        # Create RGB composite (B4, B3, B2 = indices 2, 1, 0)\n",
    "        rgb = data[0, [2, 1, 0], :, :]  # (3, 128, 128)\n",
    "        rgb = np.transpose(rgb, (1, 2, 0))  # (128, 128, 3)\n",
    "        \n",
    "        # Normalize for display\n",
    "        rgb = (rgb - rgb.min()) / (rgb.max() - rgb.min() + 1e-8)\n",
    "        rgb = np.clip(rgb * 2.5, 0, 1)  # Brightness adjustment\n",
    "        \n",
    "        ax = axes[i]\n",
    "        ax.imshow(rgb)\n",
    "        class_name = 'Cereal' if row['class'] == 1 else 'Non-Cereal'\n",
    "        ax.set_title(f\"Patch {row['patch_id']} ({class_name})\\n{row['split']}\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for i in range(len(successful_downloads[:8]), 8):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Extracted Sentinel-2 Patches (RGB: B4-B3-B2)', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTPUT_DIR / 'extracted_patches_preview.png', dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nPreview saved to: {OUTPUT_DIR / 'extracted_patches_preview.png'}\")\n",
    "else:\n",
    "    print(\"No patches to visualize - run extraction first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd59a353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
